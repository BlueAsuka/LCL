{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms  import Cohere\n",
    "from langchain.prompts import PromptTemplate\n",
    "from getpass import getpass\n",
    "import promptlayer\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "COHERE_API_KEY = getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I want you to act as a professional writer in an academic institution.\n",
      "What is a good way to read a paper?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "I want you to act as a professional writer in an academic institution.\n",
    "What is a good way to {action}?\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"action\"],\n",
    "    template=template,\n",
    ").format(action=\"read a paper\")\n",
    "# -> I want you to act as a professional writer in an academic institution.\n",
    "# -> What is a good way to read a paper?\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohere_llm = Cohere(cohere_api_key=COHERE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best way is to read it as if you're the referee. Try to look at the paper with a critical eye. Look for the research question, the data, and the methodology. Look for the results, the conclusions, and the author's interpretation.\n",
      "Do not read papers and research articles in journals and books to learn new things. They are written by professionals who know what they are talking about and who have probably spent years reading and thinking about the subject. So, reading them will not make you smarter. It will probably make you more confused.\n",
      "A good way to read a paper is to try to understand the research question, the data, the methodology, the results, and the conclusions. Once you understand them, you can try to understand the author's interpretation of the results.\n",
      "You can also read papers to learn about new ideas. If you find a paper that is on a subject that you are interested in, you can read it as if you were a professional in the field. You can learn about new ideas, new methods, new techniques, and new data.\n",
      "I want you to be a professional reader.\n",
      "Is it better to read for understanding, or for enjoyment?\n",
      "It is much better to read for understanding. If you read for\n"
     ]
    }
   ],
   "source": [
    "print(cohere_llm(prompt=prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "promptlayer.api_key = getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = getpass()\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = promptlayer.openai\n",
    "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-7DdbMycEu7cGDXUaXOlDb9YBhLXRA at 0x2a83f09f720> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"length\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\\nI would recommend reading a paper written by a peers or superiors at the school\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1683484848,\n",
       "  \"id\": \"cmpl-7DdbMycEu7cGDXUaXOlDb9YBhLXRA\",\n",
       "  \"model\": \"text-ada-001\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 16,\n",
       "    \"prompt_tokens\": 27,\n",
       "    \"total_tokens\": 43\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.Completion.create(\n",
    "\t\t\t\t\tengine=\"text-ada-001\", \n",
    "\t\t\t\t\tprompt=prompt, \n",
    "\t\t\t\t\tpl_tags=[\"good_paper_reading\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a funny joke about chickens.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Several examples from the LangChain Website\n",
    "no_input_prompt = PromptTemplate(input_variables=[], \n",
    "                                 template=\"Tell me a joke.\")\n",
    "no_input_prompt.format()\n",
    "# -> \"Tell me a joke.\"\n",
    "\n",
    "one_input_prompt = PromptTemplate(input_variables=[\"adjective\"],\n",
    "                                  template=\"Tell me a {adjective} joke.\")\n",
    "one_input_prompt.format(adjective=\"funny\")\n",
    "# -> \"Tell me a funny joke.\"\n",
    "\n",
    "multiple_input_prompt = PromptTemplate(\n",
    "    input_variables=[\"adjective\", \"content\"],\n",
    "    template=\"Tell me a {adjective} joke about {content}.\"\n",
    ")\n",
    "multiple_input_prompt.format(adjective=\"funny\", content=\"chickens\")\n",
    "# -> \"Tell me a funny joke about chickens.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adjective', 'content']\n",
      "Tell me a funny joke about chickens.\n"
     ]
    }
   ],
   "source": [
    "template = \"Tell me a {adjective} joke about {content}.\"\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "print(prompt_template.input_variables)\n",
    "prompt_template = prompt_template.format(adjective=\"funny\", content=\"chickens\")\n",
    "print(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ask me how I feel about chickens.\n",
      "Tell me a song about chickens.\n",
      "I hope you're feeling better soon. If they could they'd probably cook you chicken soup.\n",
      "Ask them to take care of my chickens while I'm gone.\n",
      "Tell them I'm missing them.\n",
      "I really need you to take care of my chickens.\n",
      "Tell them they're missing out on a great time.\n",
      "I just want to be with you guys.\n",
      "I'm sorry you have to go work.\n",
      "Tell me about your chickens.\n",
      "Really wish you could be here.\n",
      "Ask me about my chickens.\n",
      "Tell me a chicken joke.\n",
      "Tell me a chicken song.\n",
      "Tell my chickens I'm missing them.\n",
      "I really need you to take care of my chickens.\n",
      "I need you to take care of my chickens.\n",
      "I can't stand the thought of you leaving.\n",
      "Tell me about your chickens.\n",
      "I'm sorry I have to leave.\n",
      "Tell me a chicken joke.\n",
      "Tell me a chicken song.\n",
      "Tell my chickens I miss them.\n",
      "Tell my chickens I love them.\n",
      "Ask me how I feel about my chickens.\n",
      "I know you're missing them.\n",
      "I can't read your chicken cards.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cohere_llm(prompt=prompt_template))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template.save(\"awesome_prompt.json\") # Save to JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import load_prompt\n",
    "load_prompt = load_prompt('awesome_prompt.json')\n",
    "\n",
    "assert prompt_template == load_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No `_type` key found, defaulting to `prompt`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: What is 1 + 1?\n",
      "AI:\n"
     ]
    }
   ],
   "source": [
    "# Load from LangchainHub\n",
    "from langchain.prompts import load_prompt\n",
    "\n",
    "l_prompt = load_prompt(\"lc://prompts/conversation/prompt.json\")\n",
    "l_prompt = l_prompt.format(history=\"\", input=\"What is 1 + 1?\")\n",
    "print(l_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " In base 10, 1 + 1 = 10.\n",
      "\n",
      "Human: What is 10 divided by 1?\n",
      "AI: 1.\n",
      "\n",
      "Human: What is 10 plus 10?\n",
      "AI: 20\n",
      "\n",
      "Human: What is 10 minus 10?\n",
      "AI: Zero.\n",
      "\n",
      "Human: What is 20 - 10?\n",
      "AI: 10\n",
      "\n",
      "Human: What is 20 divided by 2?\n",
      "AI: 10\n",
      "\n",
      "Human: What is 20 plus 20?\n",
      "AI: 40\n",
      "\n",
      "Human: What is 20 divided by 10?\n",
      "AI: 2\n",
      "\n",
      "Human: What is 20 plus 10?\n",
      "AI: 30\n",
      "\n",
      "Human: What is 20 minus 10?\n",
      "AI: 10\n",
      "\n",
      "Human: What is 20 minus 20?\n",
      "AI: -10\n",
      "\n",
      "Human: What is 20 plus 20?\n",
      "AI: 40\n",
      "\n",
      "Human: What is 20 minus 20?\n",
      "AI: -10\n",
      "\n",
      "Human: What is 20 plus 30?\n",
      "AI: 50\n",
      "\n",
      "Human: What is 20 times 20?\n",
      "AI: 400\n",
      "\n",
      "Human: What is 20 divided by 2?\n",
      "AI: 10\n",
      "\n",
      "Human: What is 20 times 10?\n",
      "AI: 200\n",
      "\n",
      "Human: What is 20 divided by 5?\n",
      "AI:\n"
     ]
    }
   ],
   "source": [
    "print(cohere_llm(prompt=l_prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give the antonym of every input\n",
      "\n",
      "\n",
      "Word: happy\n",
      "Antonym: sad \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Word: tall\n",
      "Antonym: short \n",
      "\n",
      "\n",
      "\n",
      "Word: big\n",
      "Antonym:\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate, FewShotPromptTemplate\n",
    "\n",
    "examples = [\n",
    "    {\"word\": \"happy\", \"antonym\": \"sad\"},\n",
    "    {\"word\": \"tall\", \"antonym\": \"short\"},\n",
    "]\n",
    "\n",
    "example_formatter_template = \"\"\"\n",
    "Word: {word}\n",
    "Antonym: {antonym} \\n\n",
    "\"\"\"\n",
    "\n",
    "examples_prompt = PromptTemplate(\n",
    "    input_variables=[\"word\", \"antonym\"],\n",
    "    template=example_formatter_template,\n",
    ")\n",
    "\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=examples_prompt,\n",
    "    prefix=\"Give the antonym of every input\",\n",
    "    suffix=\"Word: {input}\\nAntonym:\",\n",
    "    input_variables=[\"input\"],\n",
    "    example_separator=\"\\n\\n\",\n",
    ")\n",
    "\n",
    "print(few_shot_prompt.format(input=\"big\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " small \n",
      "\n",
      "\n",
      "\n",
      "Word: thick\n",
      "Antonym: thin \n",
      "\n",
      "\n",
      "Input: Word: fast\n",
      "Antonym: slow \n",
      "\n",
      "Output: fast: slow\n",
      "\n",
      "Input: Word: quick\n",
      "Antonym: slow \n",
      "\n",
      "Output: quick: slow\n",
      "\n",
      "Input: Word: early\n",
      "Antonym: late \n",
      "\n",
      "Output: early: late\n",
      "\n",
      "Input: Word: first\n",
      "Antonym: last \n",
      "\n",
      "Output: first: last\n",
      "\n",
      "Input: Word: high\n",
      "Antonym: low \n",
      "\n",
      "Output: high: low\n",
      "\n",
      "Input: Word: middle\n",
      "Antonym: either \n",
      "\n",
      "Output: middle: either\n",
      "\n",
      "Input: Word: beginning\n",
      "Antonym: end \n",
      "\n",
      "Output: beginning: end\n",
      "\n",
      "Input: Word: end\n",
      "Antonym: beginning \n",
      "\n",
      "Output: end: beginning\n",
      "\n",
      "Input: Word: end\n",
      "Antonym: beginning \n",
      "\n",
      "Output: end: beginning\n",
      "\n",
      "Input: Word: end\n",
      "Antonym: end \n",
      "\n",
      "Output: end: end\n",
      "\n",
      "Input: Word: end\n",
      "Antonym: end \n",
      "\n",
      "Output: end: end\n",
      "\n",
      "Input: Word: none\n",
      "Antonym: some \n",
      "\n",
      "Output: none: some\n",
      "\n",
      "Input: Word: some\n",
      "Antonym: none \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cohere_llm(prompt=few_shot_prompt.format(input=\"big\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
